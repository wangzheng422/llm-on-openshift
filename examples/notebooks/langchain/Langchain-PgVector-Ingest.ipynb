{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3420575b-4d00-458b-aa0e-7030008ccd53",
   "metadata": {},
   "source": [
    "## Creating an index and populating it with documents using PostgreSQL+pgvector\n",
    "\n",
    "Simple example on how to ingest PDF documents, then web pages content into a PostgreSQL+pgvector VectorStore.\n",
    "\n",
    "Requirements:\n",
    "- A PostgreSQL cluster with the pgvector extension installed (https://github.com/pgvector/pgvector)\n",
    "- A Database created in the cluster with the extension enabled (in this example, the database is named `vectordb`. Run the following command in the database as a superuser:\n",
    "`CREATE EXTENSION vector;`\n",
    "\n",
    "Note: if your PostgreSQL is deployed on OpenShift, directly from inside the Pod (Terminal view on the Console, or using `oc rsh` to log into the Pod), you can run the command: `psql -d vectordb -c \"CREATE EXTENSION vector;\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b229-b520-4e82-a783-eb921bb955e7",
   "metadata": {},
   "source": [
    "### Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pgvector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82063d-6153-4812-8977-042241736b53",
   "metadata": {},
   "source": [
    "### Base parameters, the PostgreSQL info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417ed4a4-9418-4f48-bebd-ef0ea11ae434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"postgresql+psycopg://user:password@postgresql-server:5432/vectordb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b499a49-128c-4be5-903b-76c40771c7bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600cd763-6ecc-4c77-89c0-47108c31c44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f6785-480e-4519-be4f-8e1738dba4ca",
   "metadata": {},
   "source": [
    "## Initial index creation and document ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cff5f7-c509-48db-90b5-e15815b8b530",
   "metadata": {},
   "source": [
    "#### Document loading from a folder containing PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde8a4a3-d602-49c6-b4a5-31a76b25a58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_folder_path = './rhods-doc'\n",
    "\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198fe0a-38bf-4cd4-af7d-35b41c645edd",
   "metadata": {},
   "source": [
    "#### Split documents into chunks with some overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edba4a08-2194-4df1-9091-6f2b596757a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Red Hat OpenShift Data Science self-\\nmanaged\\n \\n1.32\\nUpgrading OpenShift Data Science self-\\nmanaged in a disconnected environment\\nLearn how to upgrade Red Hat OpenShift Data Science on OpenShift Container\\nPlatform in a disconnected environment\\nLast Updated: 2023-09-05', metadata={'source': 'rhods-doc/red_hat_openshift_data_science_self-managed-1.32-upgrading_openshift_data_science_self-managed_in_a_disconnected_environment-en-us.pdf', 'page': 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,\n",
    "                                               chunk_overlap=40)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup documents as PostgreSQL won't accept the NUL character, '\\x00', in TEXT fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aefc08d-a4ad-4aad-9120-cfa98b67cbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in all_splits:\n",
    "    doc.page_content = doc.page_content.replace('\\x00', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7eae2-c670-4eb5-803b-b4d591fa83db",
   "metadata": {},
   "source": [
    "#### Create the index and ingest the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "COLLECTION_NAME = \"documents_test\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489c6e6d-c42c-4de4-87cf-8edfd0e63da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How do you install OpenShift Data Science?\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90feeb37-7888-4c5f-a5cb-5f82637cec16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.22300212246166795\n",
      "CHAPTER 2. OVERVIEW OF INSTALLING AND DEPLOYING\n",
      "OPENSHIFT DATA SCIENCE\n",
      "Red Hat OpenShift Data Science is a platform for data scientists and developers of artificial intelligence\n",
      "(AI) applications. It provides a fully supported environment that lets you rapidly develop, train, test, and\n",
      "deploy machine learning models on-premises and/or in the public cloud.\n",
      "OpenShift Data Science is provided as a managed cloud service add-on for Red Hat OpenShift or as\n",
      "self-managed software that you can install on-premise or in the public cloud on OpenShift. For\n",
      "information on installing OpenShift Data Science as a managed cloud service add-on, see \n",
      "Installing\n",
      "OpenShift Data Science\n",
      ".\n",
      "Installing OpenShift Data Science involves the following high-level tasks:\n",
      "1\n",
      ". \n",
      "Confirm that your OpenShift Container Platform cluster meets all requirements.\n",
      "2\n",
      ". \n",
      "Configure an identity provider for OpenShift Container Platform.\n",
      "3\n",
      ". \n",
      "Add administrative users for OpenShift Container Platform.\n",
      "4\n",
      ". \n",
      "Install the OpenShift Data Science Operator.\n",
      "5\n",
      ".\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.22300212246166795\n",
      "CHAPTER 2. OVERVIEW OF INSTALLING AND DEPLOYING\n",
      "OPENSHIFT DATA SCIENCE\n",
      "Red Hat OpenShift Data Science is a platform for data scientists and developers of artificial intelligence\n",
      "(AI) applications. It provides a fully supported environment that lets you rapidly develop, train, test, and\n",
      "deploy machine learning models on-premises and/or in the public cloud.\n",
      "OpenShift Data Science is provided as a managed cloud service add-on for Red Hat OpenShift or as\n",
      "self-managed software that you can install on-premise or in the public cloud on OpenShift. For\n",
      "information on installing OpenShift Data Science as a managed cloud service add-on, see \n",
      "Installing\n",
      "OpenShift Data Science\n",
      ".\n",
      "Installing OpenShift Data Science involves the following high-level tasks:\n",
      "1\n",
      ". \n",
      "Confirm that your OpenShift Container Platform cluster meets all requirements.\n",
      "2\n",
      ". \n",
      "Configure an identity provider for OpenShift Container Platform.\n",
      "3\n",
      ". \n",
      "Add administrative users for OpenShift Container Platform.\n",
      "4\n",
      ". \n",
      "Install the OpenShift Data Science Operator.\n",
      "5\n",
      ".\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.23196910905560153\n",
      ".\n",
      "The \n",
      "Installed Operators\n",
      " page opens.\n",
      "CHAPTER 3. UPGRADING OPENSHIFT DATA SCIENCE IN A DISCONNECTED ENVIRONMENT\n",
      "7\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.23196910905560153\n",
      ".\n",
      "The \n",
      "Installed Operators\n",
      " page opens.\n",
      "CHAPTER 3. UPGRADING OPENSHIFT DATA SCIENCE IN A DISCONNECTED ENVIRONMENT\n",
      "7\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d4869-be21-4cf4-a72c-2e58bcc1ab43",
   "metadata": {},
   "source": [
    "## Ingesting new documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3052c81-7652-4ef0-acaf-883608a9ff85",
   "metadata": {},
   "source": [
    "#### Example with Web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998bcc21-d03c-4889-83a6-09c62cab25eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354cfe78-9d90-404a-8648-98fb2e79ff6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader([\"https://ai-on-openshift.io/getting-started/openshift/\",\n",
    "                        \"https://ai-on-openshift.io/getting-started/opendatahub/\",\n",
    "                        \"https://ai-on-openshift.io/getting-started/openshift-data-science/\",\n",
    "                        \"https://ai-on-openshift.io/odh-rhods/configuration/\",\n",
    "                        \"https://ai-on-openshift.io/odh-rhods/custom-notebooks/\",\n",
    "                        \"https://ai-on-openshift.io/odh-rhods/nvidia-gpus/\",\n",
    "                        \"https://ai-on-openshift.io/odh-rhods/custom-runtime-triton/\",\n",
    "                        \"https://ai-on-openshift.io/odh-rhods/openshift-group-management/\",\n",
    "                        \"https://ai-on-openshift.io/tools-and-applications/minio/minio/\"\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab4eaf5-d177-4410-ae9d-a012f7ffafad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92838fe4-5b33-4835-b7e3-643ddef952c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,\n",
    "                                               chunk_overlap=40)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "for doc in all_splits:\n",
    "    doc.page_content = doc.page_content.replace('\\x00', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd66d87-8314-4b2f-9c02-e856e1035e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "store = PGVector(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2355aa-5096-482a-ac39-4d285e63fb39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store.add_documents(all_splits);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
